// Generated by CoffeeScript 1.10.0
(function() {
  var CoffeeLint, MAX_GPA, MIN_GPA, analyze, churn, clamp, coffee, complexFilePenalty, complexityConfig, cyclomaticComplexity, divide, execSync, files, fs, functionLength, functionLengthConfig, glob, gpa, letterGrade, longFilePenalty, longFunctionPenalty, nestedCoffeeScriptPattern, rawGpa, report, rules, tokenComplexity, tokens, version;

  version = require("../package.json").version;

  execSync = require("child_process").execSync;

  coffee = require("coffee-script");

  require("coffee-script/register");

  tokens = coffee.tokens;

  CoffeeLint = require("coffeelint");

  CoffeeLint.registerRule(require("coffeelint-no-long-functions"));

  MIN_GPA = 0;

  MAX_GPA = 4;

  complexityConfig = {
    cyclomatic_complexity: {
      value: 0,
      level: "error"
    }
  };

  functionLengthConfig = {
    no_long_functions: {
      value: 0,
      level: "error"
    }
  };

  rules = require("./rules");

  fs = require("fs");

  glob = require("glob");

  nestedCoffeeScriptPattern = function(path) {
    return path + "/**/*\.+(coffee|coffee\.md|litcoffee)";
  };

  clamp = function(number, min, max) {
    return Math.max(Math.min(max, number), min);
  };

  divide = function(numerator, denominator) {
    if (denominator) {
      return numerator / denominator;
    } else {
      return 0;
    }
  };

  functionLength = function(file) {
    var max, output, sum;
    sum = max = 0;
    output = CoffeeLint.lint(file, functionLengthConfig).reduce(function(hash, description) {
      var length, lineRange;
      if (description.rule === "no_long_functions") {
        lineRange = description.lineNumber + "-" + description.lineNumberEnd;
        length = description.lineNumberEnd - description.lineNumber;
        hash.lines[lineRange] = length;
        sum += length;
        if (length > max) {
          max = length;
        }
      }
      return hash;
    }, {
      lines: {}
    });
    output.average = divide(sum, Object.keys(output.lines).length);
    output.max = max;
    return output;
  };

  cyclomaticComplexity = function(file) {
    var max, output, sum;
    sum = max = 0;
    output = CoffeeLint.lint(file, complexityConfig).reduce(function(hash, description) {
      var lineRange;
      if (description.rule === "cyclomatic_complexity") {
        lineRange = description.lineNumber + "-" + description.lineNumberEnd;
        hash.lines[lineRange] = description.context;
        sum += description.context;
        if (description.context > max) {
          max = description.context;
        }
      }
      return hash;
    }, {
      lines: {}
    });
    output.average = divide(sum, Object.keys(output.lines).length);
    output.max = max;
    output.total = sum;
    return output;
  };

  churn = function(filePath) {
    var command, output;
    command = "git whatchanged " + filePath + " | grep 'commit' | wc -l";
    output = execSync(command);
    return parseInt(output, 10);
  };

  tokenComplexity = function(tokens) {
    return tokens.reduce(function(sum, token) {
      var type;
      type = token[0];
      return sum += rules[type] || 0;
    }, 0);
  };

  complexFilePenalty = function(complexity) {
    if ((0 <= complexity && complexity <= 20)) {
      return 1;
    } else if ((20 < complexity && complexity <= 30)) {
      return 0.9;
    } else if ((30 < complexity && complexity <= 40)) {
      return 0.8;
    } else if (complexity > 40) {
      return 0.7;
    }
  };

  longFunctionPenalty = function(averageFunctionLength) {
    if ((0 <= averageFunctionLength && averageFunctionLength <= 20)) {
      return 1;
    } else if ((20 < averageFunctionLength && averageFunctionLength <= 40)) {
      return 0.9;
    } else if ((40 < averageFunctionLength && averageFunctionLength <= 60)) {
      return 0.8;
    } else if (averageFunctionLength > 60) {
      return 0.7;
    }
  };

  longFilePenalty = function(tokens) {
    if ((0 <= tokens && tokens <= 1000)) {
      return 1;
    } else if ((1000 < tokens && tokens <= 2000)) {
      return 0.9;
    } else if ((2000 < tokens && tokens <= 4000)) {
      return 0.8;
    } else if (tokens > 4000) {
      return 0.7;
    }
  };

  letterGrade = function(numericGrade) {
    if ((0 <= numericGrade && numericGrade <= 0.8)) {
      return "F";
    } else if ((0.8 < numericGrade && numericGrade <= 1.6)) {
      return "D";
    } else if ((1.6 < numericGrade && numericGrade <= 2.4)) {
      return "C";
    } else if ((2.4 < numericGrade && numericGrade <= 3.2)) {
      return "B";
    } else if ((3.2 < numericGrade && numericGrade <= 4)) {
      return "A";
    }
  };

  rawGpa = function(file, tokens) {
    var raw, tokenCount;
    tokenCount = tokens.length;
    if (!tokenCount) {
      return 0;
    }
    raw = tokenCount / tokenComplexity(tokens);
    return raw * MAX_GPA;
  };

  gpa = function(base, penalties) {
    var penalized;
    penalized = base * penalties.filePenalty * penalties.functionPenalty * penalties.complexityPenalty;
    return clamp(penalized, MIN_GPA, MAX_GPA);
  };

  files = function(paths) {
    return paths.reduce(function(list, path) {
      var pattern, stats;
      stats = fs.lstatSync(path);
      if (stats.isFile()) {
        list.push(path);
      } else if (stats.isDirectory()) {
        pattern = nestedCoffeeScriptPattern(path);
        list = list.concat(glob.sync(pattern));
      }
      return list;
    }, []);
  };

  analyze = function(filePath) {
    var cComplexity, fLength, file, fileTokens, numericGrade, raw;
    file = fs.readFileSync(filePath, "utf8");
    fileTokens = tokens(file, {
      literate: coffee.helpers.isLiterate(filePath)
    });
    fLength = functionLength(file);
    cComplexity = cyclomaticComplexity(file);
    raw = rawGpa(file, fileTokens);
    numericGrade = gpa(raw, {
      filePenalty: longFilePenalty(fileTokens.length),
      functionPenalty: longFunctionPenalty(fLength.average),
      complexityPenalty: complexFilePenalty(cComplexity.total)
    });
    return {
      gpa: numericGrade,
      letterGrade: letterGrade(numericGrade),
      churn: churn(filePath),
      functionLength: fLength,
      cyclomaticComplexity: cComplexity,
      tokenComplexity: tokenComplexity(fileTokens),
      tokenCount: fileTokens.length
    };
  };

  report = function(filePaths, opts) {
    var scores;
    if (opts == null) {
      opts = {};
    }
    scores = files(filePaths).reduce(function(hash, file) {
      hash[file] = analyze(file);
      return hash;
    }, {});
    return JSON.stringify(scores, null, opts.indentSpace);
  };

  exports.clog = {
    report: report,
    VERSION: version
  };

}).call(this);
